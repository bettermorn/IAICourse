{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decent-playback",
   "metadata": {},
   "source": [
    "# Chapter 10: Cluster Randomization and Hierarchical Modeling 聚类随机化与分层建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a8242-c608-4400-a840-cee98ca7edb0",
   "metadata": {},
   "source": [
    "# 代码来源：\n",
    "https://github.com/BuissonFlorent/BehavioralDataAnalysis/tree/master/Chapter%2010%20-%20Cluster%20Randomization%20and%20Hierarchical%20Modeling\n",
    "# 本实验验证：\n",
    "新的SOP让顾客在互动过程中有更好体验，即获得更高的CSAT（每月顾客平均满意度）测量值。\n",
    "# 在设计A/B测试时，回答以下问题：\n",
    "1. 需要多少样本量才能有80%的把握检测到效应？\n",
    "2. 给定样本量，能检测到的最小效应是多少？\n",
    "3. 应该使用什么置信水平？\n",
    "# 典型工作流程：\n",
    "1. 使用历史数据估计变异性和基线值\n",
    "2. 设定目标效应大小（有意义的最小效应）\n",
    "3. 运行模拟计算不同参数组合下的功效\n",
    "4. 选择满足功效要求的实验设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-skirt",
   "metadata": {},
   "source": [
    "# Libraries and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-running",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposite-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "\n",
    "# Chapter-specific libraries\n",
    "# To rescale numeric variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# To one-hot encode cat. variables 分类数据数值化\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-michigan",
   "metadata": {},
   "source": [
    "### Data\n",
    "数据包括\n",
    "- 呼叫中心的Center_ID\n",
    "- 客服ID Rep_ID\n",
    "- 顾客年龄Age\n",
    "- 致电原因Reason\n",
    "- 顾客满意度 CALL_CSAT\n",
    "- 所属组别grp，如对照组和实验组，仅实验数据有，历史数据无\n",
    "处理数据\n",
    "- 调整中心ID以区别于索引\n",
    "- 移除不需要的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standing-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_df = pd.read_csv('chap10-historical_data.csv')\n",
    "exp_data_df = pd.read_csv('chap10-experimental_data.csv')\n",
    "\n",
    "#Shifting center_ID to distinguish it from indices 调整中心ID以区别于索引\n",
    "hist_data_df['center_ID'] = hist_data_df['center_ID'] + 100 \n",
    "exp_data_df['center_ID'] = exp_data_df['center_ID'] + 100 \n",
    "\n",
    "#Removing the variable M6Spend we won't use in this chapter 移除不需要的变量\n",
    "del(hist_data_df['M6Spend'])\n",
    "del(exp_data_df['M6Spend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-workshop",
   "metadata": {},
   "source": [
    "# Introduction to hierarchical modeling 分层建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f18870-baca-4914-afc5-f89d021a35f0",
   "metadata": {},
   "source": [
    "分层模型适用于解决多重共线性问题，也即一个分类变量依赖于另一个分类变量，即嵌套分类变量。分层模型将组视为从可能无限的组分布中随机抽取的组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surface-occasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "=============================================================\n",
      "Model:              MixedLM Dependent Variable: call_CSAT    \n",
      "No. Observations:   695205  Method:             REML         \n",
      "No. Groups:         10      Scale:              1.1217       \n",
      "Min. group size:    54203   Log-Likelihood:     -1026427.7247\n",
      "Max. group size:    79250   Converged:          Yes          \n",
      "Mean group size:    69520.5                                  \n",
      "-------------------------------------------------------------\n",
      "                   Coef. Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept          3.899    0.335  11.641 0.000  3.243  4.556\n",
      "reason[T.property] 0.199    0.003  74.786 0.000  0.194  0.205\n",
      "age                0.020    0.000 176.747 0.000  0.020  0.020\n",
      "Group Var          1.122    0.407                            \n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical analysis of historical data with center ID only as clustering variable\n",
    "# 仅以中心ID作为聚类变量的历史数据层次分析 原因和年龄 混合线性模型回归结果\n",
    "\n",
    "mixed = smf.mixedlm(\"call_CSAT ~ reason + age\", data = hist_data_df, \n",
    "                   groups = hist_data_df[\"center_ID\"])\n",
    "print(mixed.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "=============================================================\n",
      "Model:             MixedLM  Dependent Variable:  call_CSAT   \n",
      "No. Observations:  695205   Method:              REML        \n",
      "No. Groups:        10       Scale:               0.3904      \n",
      "Min. group size:   54203    Log-Likelihood:      -660424.9323\n",
      "Max. group size:   79250    Converged:           Yes         \n",
      "Mean group size:   69520.5                                   \n",
      "-------------------------------------------------------------\n",
      "                   Coef. Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept          3.901    0.367  10.639 0.000  3.182  4.620\n",
      "reason[T.property] 0.200    0.002 126.789 0.000  0.196  0.203\n",
      "age                0.020    0.000 298.302 0.000  0.020  0.020\n",
      "Group Var          1.304    0.976                            \n",
      "rep_ID Var         0.776    0.131                            \n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical analysis of historical data with center ID and rep ID as clustering variable\n",
    "# 以中心ID和代表ID为聚类变量的历史数据分层分析 混合线性模型回归结果 代表ID是嵌套在中心ID变量下的一个聚类变量。\n",
    "# 以方差和标准差的形式测量呼叫中心内部和呼叫中心之间数据的可变性。\n",
    "# 固定效应表示呼叫层次变量的系数\n",
    "vcf = {\"rep_ID\": \"0+C(rep_ID)\"} #在方差分量公式中表示低层嵌套变量\n",
    "mixed2 = smf.mixedlm(\"call_CSAT ~ reason + age\", \n",
    "                    data = hist_data_df, \n",
    "                    groups = hist_data_df[\"center_ID\"],\n",
    "                    re_formula='1',\n",
    "                    vc_formula=vcf)\n",
    "print(mixed2.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-print",
   "metadata": {},
   "source": [
    "# Determining random assignment and sample size/power 确定随机分配与样本量/检验效能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb815f15-321e-4f81-91bf-9649ca5a96cf",
   "metadata": {},
   "source": [
    "假设最小可检测效应是0.6，我们的判定规则得出实验组确实比对照组更好的概率是多少？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "circular-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for simulation # 模拟函数\n",
    "# 从分层模型返回实验组的系数\n",
    "# 采用标准功效分析统计公式，T检验公式\n",
    "def hlm_metric_fun(dat_df):\n",
    "    vcf = {\"rep_ID\": \"0+C(rep_ID)\"}\n",
    "    h_mod = smf.mixedlm(\"call_CSAT ~ reason + age + grp\", \n",
    "                   data = dat_df, \n",
    "                  groups = dat_df[\"center_ID\"],\n",
    "                    re_formula='1',\n",
    "                   vc_formula=vcf)\n",
    "    coeff = h_mod.fit().fe_params.values[2]\n",
    "    return coeff\n",
    "\n",
    "\n",
    "# 通过自助法计算指定指标的置信区间\n",
    "#通过有放回的重抽样模拟数据生成过程，从原始数据中多次抽样，每次计算统计量，用这些统计量的分布来估计真实参数的分布\n",
    "def boot_CI_fun(dat_df, metric_fun = hlm_metric_fun, B = 20, conf_level = 9/10):\n",
    "    Ncalls_rep = 1200\n",
    "    coeff_boot = []\n",
    "    # Calculate coeff of interest for each simulation #计算每次模拟中目标系数\n",
    "    for b in range(B):\n",
    "        boot_df = dat_df.groupby(\"rep_ID\").sample(n=Ncalls_rep,\n",
    "                                                  replace=True).\\\n",
    "        reset_index(drop= True)\n",
    "        coeff = metric_fun(boot_df)\n",
    "        coeff_boot.append(coeff)\n",
    "    #Extract confidence interval #提取置信区间\n",
    "    coeff_boot.sort()\n",
    "    offset = round(B * (1 - conf_level) / 2)\n",
    "    confint = [coeff_boot[offset], coeff_boot[-(offset+1)]]\n",
    "    return confint\n",
    "\n",
    "# 基于置信区间做出二元决策 \n",
    "# 决策为1：有足够的证据表明指标显著大于0\n",
    "# 决策为0：没有足够证据表明指标显著大于0\n",
    "def decision_fun(dat_df, metric_fun, B = 20, conf_level = 0.9):\n",
    "    boot_CI = boot_CI_fun(dat_df, metric_fun, B = B, conf_level = conf_level)\n",
    "    decision = 1 if boot_CI[0] > 0  else 0\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-moscow",
   "metadata": {},
   "source": [
    "## Random assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f4622-25bc-4905-8b18-c3f5c64e6d7f",
   "metadata": {},
   "source": [
    "在呼叫中心层级随机化，根据呼叫中心的特征分层，例如客服代表数量和呼叫指标的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2572810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nreps</th>\n",
       "      <th>avg_call_CSAT</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>pct_reason_pmt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3.664430</td>\n",
       "      <td>39.962880</td>\n",
       "      <td>0.601027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>21.0</td>\n",
       "      <td>3.958169</td>\n",
       "      <td>39.959532</td>\n",
       "      <td>0.599237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4.030376</td>\n",
       "      <td>39.981830</td>\n",
       "      <td>0.599508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.296561</td>\n",
       "      <td>40.063354</td>\n",
       "      <td>0.599690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.921405</td>\n",
       "      <td>39.977681</td>\n",
       "      <td>0.600679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nreps  avg_call_CSAT    avg_age  pct_reason_pmt\n",
       "center_ID                                                 \n",
       "101         18.0       3.664430  39.962880        0.601027\n",
       "102         21.0       3.958169  39.959532        0.599237\n",
       "103         22.0       4.030376  39.981830        0.599508\n",
       "104         15.0       5.296561  40.063354        0.599690\n",
       "105         21.0       5.921405  39.977681        0.600679"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating data to center level # 将数据聚合至中心层级\n",
    "center_data_df = hist_data_df.groupby('center_ID').agg(\n",
    "        nreps = ('rep_ID', lambda x: x.nunique()),\n",
    "        avg_call_CSAT = (\"call_CSAT\", \"mean\"),\n",
    "        avg_age=(\"age\", \"mean\"),\n",
    "        pct_reason_pmt=('reason', \n",
    "                        lambda x: sum(1 if r=='payment' else 0 for r in x)/len(x))\n",
    "        )\n",
    "\n",
    "#Reformatting variables as needed # 按需重新格式化变量\n",
    "center_data_df['nreps'] = center_data_df.nreps.astype(float)\n",
    "\n",
    "center_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-workstation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 101],\n",
       "       [106, 103],\n",
       "       [107, 104],\n",
       "       [110, 105],\n",
       "       [109, 108]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function to prep the data 准备数据的函数\n",
    "def strat_prep_fun(dat_df):\n",
    "\n",
    "    #Extracting components of the data  #提取数据组件\n",
    "    num_df = dat_df.copy().loc[:,dat_df.dtypes=='float64'] #Numeric vars\n",
    "    center_ID = [i for i in dat_df.index]\n",
    "\n",
    "    #Normalizing all numeric variables to [0,1] #将所有数值变量归一化至[0,1]区间\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(num_df)\n",
    "    num_np = scaler.transform(num_df)\n",
    "    \n",
    "    return center_ID, num_np\n",
    "\n",
    "# K-近邻匹配算法，采用贪心策略，\n",
    "# 在观测研究中创建匹配的控制组\n",
    "def pair_fun(dat_df, K = 2):\n",
    "    \n",
    "    match_len = K - 1 # Number of matches we want to find 需寻找的匹配对数量\n",
    "    match_idx = match_len - 1 # Accounting for 0-indexing 考虑0索引规则\n",
    "    \n",
    "    center_ID, data_np = strat_prep_fun(dat_df)\n",
    "    N = len(data_np)\n",
    "    \n",
    "    #Calculate distance matrix 计算距离矩阵\n",
    "    from scipy.spatial import distance_matrix\n",
    "    d_mat = distance_matrix(data_np, data_np)\n",
    "    np.fill_diagonal(d_mat,N+1)\n",
    "    # Set up variables 设置变量\n",
    "    available = [i for i in range(N)]\n",
    "    available_temp = available.copy()\n",
    "    matches_lst = []\n",
    "    lim = int(N/match_len)\n",
    "    \n",
    "    closest = np.argpartition(d_mat, kth=match_idx,axis=1)\n",
    "    \n",
    "    for n in available:\n",
    "        if len(matches_lst) == lim: break\n",
    "        if n in available_temp:\n",
    "            for match_lim in range(match_idx,N-1):\n",
    "                possible_matches = closest[n,:match_lim].tolist()\n",
    "                matches = list(set(available_temp) & set(possible_matches))\n",
    "                if len(matches) == match_len:\n",
    "                    matches.append(n)\n",
    "                    matches_lst.append(matches)\n",
    "                    available_temp \\\n",
    "                    = [m for m in available_temp if m not in matches]\n",
    "                    break\n",
    "                else:\n",
    "                    closest[n,:] = np.argpartition(d_mat[n,:], kth=match_lim)\n",
    "    #Map center indices to their proper IDs #将中心索引映射至对应ID\n",
    "    matches_id_lst = [[center_ID[k[0]],center_ID[k[1]]] for k in matches_lst]\n",
    "    return np.array(matches_id_lst)\n",
    "pair_fun(center_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-pride",
   "metadata": {},
   "source": [
    "## Power analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055e501-8d34-414d-bc53-dd732339ebfa",
   "metadata": {},
   "source": [
    "功效分析模拟函数，用于评估统计检验检测给定效应大小的能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "national-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simulation function 模拟函数#####\n",
    "def power_sim_fun(dat_df, metric_fun = hlm_metric_fun, Ncalls_rep = 1000, eff_size = 1, B = 20, conf_level = 0.9):\n",
    "    \"\"\"\n",
    "    功能：模拟A/B测试并计算统计功效\n",
    "    参数：\n",
    "      - dat_df: 包含实验数据的DataFrame\n",
    "      - metric_fun: 用于计算效应量的函数，默认使用hlm_metric_fun\n",
    "      - Ncalls_rep: 每组的重抽样数量，默认1000\n",
    "      - eff_size: 模拟的效应大小（加到处理组的call_CSAT上），默认1\n",
    "      - B: 自助法重抽样次数，默认20\n",
    "      - conf_level: 置信水平，默认0.9（90%）\n",
    "    返回：包含每次模拟决策结果的列表（1=检测到效应，0=未检测到）\n",
    "    \"\"\" \n",
    "    # 不同参数对功效的影响：\n",
    "    # 1. eff_size：效应大小越大，功效越高\n",
    "    # 2. Ncalls_rep：样本量越大，功效越高\n",
    "    # 3. B：自助法迭代次数越多，置信区间估计越稳定\n",
    "    # 4. conf_level：置信水平越高，检测要求越严格，功效越低\n",
    "    #Extract the stratified pairs 提取分层配对数据\n",
    "    stratified_pairs = stratified_assgnt_fun(dat_df, K=2)\n",
    "    Npairs = len(stratified_pairs)\n",
    "    Nperm = 2 ** Npairs\n",
    "    power_list = []\n",
    "    \n",
    "    for m in dat_df.month.unique():\n",
    "        #Sample down the data 抽样数据\n",
    "        sample_data_df = dat_df.loc[dat_df.month==m,]\n",
    "        sample_data_df = sample_data_df.groupby('rep_ID')\\\n",
    "        .sample(n=Ncalls_rep, replace=True)\\\n",
    "        .reset_index(drop = True)\n",
    "        # 遍历所有可能的分配方案，完全随机化检验，在每种分配下，添加预设的效应大小，检验统计方法是否能检测到这个已知效应\n",
    "        for perm in range(Nperm):\n",
    "            bin_str = f'{perm:0{Npairs}b}'\n",
    "            idx = np.array([[i for i in range(Npairs)],\n",
    "                            [int(d) for d in bin_str]]).T\n",
    "            treat = [stratified_pairs[tuple(idx[i])] for i in range(Npairs)]\n",
    "            \n",
    "            sim_data_df = sample_data_df.copy()\n",
    "            sim_data_df['group'] = 'ctrl'\n",
    "            sim_data_df.loc[(sim_data_df.center_ID.isin(treat)),'group']\\\n",
    "                = 'treat'\n",
    "            \n",
    "            sim_data_df.loc[(sim_data_df.group=='treat'),'call_CSAT'] =\\\n",
    "                sim_data_df.loc[(sim_data_df.group=='treat'),'call_CSAT'] + eff_size\n",
    "                \n",
    "            sim_data_df.loc[(sim_data_df.call_CSAT > 10), 'call_CSAT'] = 10\n",
    "\n",
    "            # 统计决策\n",
    "            # Option 1: extract CIs for visualization 方案1：提取置信区间用于可视化\n",
    "            #sim_CI = boot_CI_fun(sim_data_df, lm_metric_fun)\n",
    "            #power_list.append(sim_CI)\n",
    "            \n",
    "            # Option 2: calculate decision for overall power determination 方案2：计算整体功效判定决策\n",
    "            D = decision_fun(sim_data_df, metric_fun, B = B, conf_level = conf_level)\n",
    "            power_list.append(D)\n",
    "            \n",
    "    return power_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-carter",
   "metadata": {},
   "source": [
    "# Analyzing the experiment 分析实验\n",
    "用度量函数分析实验数据，获得度量值的Bootstrap 90%-CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metropolitan-texas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47790322079110353\n",
      "[np.float64(0.47474867983408076), np.float64(0.4815910175343983)]\n"
     ]
    }
   ],
   "source": [
    "##### Analysis of experimental data #####\n",
    "\n",
    "coeff = hlm_metric_fun(exp_data_df)\n",
    "print(coeff)\n",
    "\n",
    "hlm_CI = boot_CI_fun(exp_data_df, hlm_metric_fun)\n",
    "print(hlm_CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bf6ef-c759-41e2-a76d-2f1aac4797c8",
   "metadata": {},
   "source": [
    "# 说明：\n",
    "置信区间非常窄，在0.25以上。根据功效分析，真实效应值不太可能在这个CI内,而是可能更低,也可能更高,预期效应值等于0.48，高于决策阈值，将实施干预，尽管预期效应值小于目标效应。置信区间比根据正态近似得到的置信区间(即系数+/-1.96*系数标准误差)小得多，部分原因在于分层随机化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
